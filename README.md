# Машинное обучение
***
### Метрические алгоритмы
Метрические алгоритмы классифицируют объекты в зависимости от их сходства, а для оценки сходства объектов используют функцию расстояния, называемую метрикой. Чем меньше расстояние, тем больше объекты похожи друг на друга.
***
##### 1NN
 Этот алгоритм является частным случаем KNN. Использя его мы измеряем расстояние классифицируемого обьекта до всех элементов выборки.
###### Функция для 1NN
```R
nn <- function(z, xl) 
{                       #Определяем размер выборки
  l <- nrow(xl)         #Строки 150       
  n <- ncol(xl)-1       #Колонки 2 ( изначально было 3 в выборке xl)
  distances <- c()      #Используем вектор расстояния
  for (i in 1:l)
  {
    distances <- c(distances, euclideanDistance(xl[i, 1:n], z))
  }
  xl[order(distances)[1], n+1]
} 
```

###### Получаем следующую карту классификации
![Иллюстрация к проекту](https://github.com/MinaevYuriy/SMPR/blob/master/1G_7rOwyOS4.jpg)

***
### Баесовские алгоритмы
Байесовский подход является классическим в теории распознавания образов и лежит в основе многих методов.
```R
naive = function(x, Py, mu, sigm, m, n) { 
  mina <- matrix(c('setosa','versicolor', 'virginica', 0, 0, 0), nrow = 3, ncol = 2)
  scores = rep(0, m)
  for (i in 1:m) {
    scores[i] = Py[i]
    for (j in 1:n){
      N=1/sqrt(2*pi)/sigm[i,j]*exp(-1/2*(x[j]-mu[i,j])^2/sigm[i,j]^2)
      scores[i] = scores[i] * N
    }
    mina[i,2]=scores[i]
  }
  class <- mina[,1][which.max(mina[,2])]
}

```
###### Получаем следующую карту классификации
![Иллюстрация к проекту](https://github.com/MinaevYuriy/SMPR/blob/master/yN3XIGM0m0I.jpg)
    
      


